{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from google.adk.sessions import InMemorySessionService\n",
    "# @title Step 0: Setup and Installation\n",
    "# Install ADK and LiteLLM for multi-model support\n",
    "\n",
    "!pip install google-adk -q\n",
    "!pip install litellm -q\n",
    "\n",
    "print(\"Installation complete.\")"
   ],
   "id": "99a52017cc62bab5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T11:59:00.761973Z",
     "start_time": "2025-11-03T11:59:00.681546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# @title Import necessary libraries\n",
    "import os\n",
    "import asyncio\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm # For multi-model support\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types # For creating message Content/Parts\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ],
   "id": "14cd9c9876c350c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T11:59:09.859275Z",
     "start_time": "2025-11-03T11:59:09.819160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Gemini API Key (Get from Google AI Studio: https://aistudio.google.com/app/apikey)\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDL3NKG54dMUzQXIFdOZbwM-HHmgPycwyA\"\n",
    "\n",
    "# [Optional]\n",
    "# OpenAI API Key (Get from OpenAI Platform: https://platform.openai.com/api-keys)\n",
    "os.environ['OPENAI_API_KEY'] = 'YOUR_OPENAI_API_KEY'\n",
    "\n",
    "# [Optional]\n",
    "# Anthropic API Key (Get from Anthropic Console: https://console.anthropic.com/settings/keys)\n",
    "os.environ['ANTHROPIC_API_KEY'] = 'YOUR_ANTHROPIC_API_KEY'\n",
    "\n",
    "# --- Verify Keys (Optional Check) ---\n",
    "print(\"API Keys Set:\")\n",
    "print(f\"Google API Key set: {'Yes' if os.environ.get('GOOGLE_API_KEY') and os.environ['GOOGLE_API_KEY'] != 'YOUR_GOOGLE_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
    "print(f\"OpenAI API Key set: {'Yes' if os.environ.get('OPENAI_API_KEY') and os.environ['OPENAI_API_KEY'] != 'YOUR_OPENAI_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
    "print(f\"Anthropic API Key set: {'Yes' if os.environ.get('ANTHROPIC_API_KEY') and os.environ['ANTHROPIC_API_KEY'] != 'YOUR_ANTHROPIC_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
    "\n",
    "# Configure ADK to use API keys directly (not Vertex AI for this multi-model setup)\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"False\""
   ],
   "id": "749bd5cc457a781",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Keys Set:\n",
      "Google API Key set: Yes\n",
      "OpenAI API Key set: No (REPLACE PLACEHOLDER!)\n",
      "Anthropic API Key set: No (REPLACE PLACEHOLDER!)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T11:59:14.330793Z",
     "start_time": "2025-11-03T11:59:14.313934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Define Model Constants for easier use ---\n",
    "\n",
    "# More supported models can be referenced here: https://ai.google.dev/gemini-api/docs/models#model-variations\n",
    "MODEL_GEMINI_2_0_FLASH = \"gemini-2.5-flash\"\n",
    "\n",
    "# More supported models can be referenced here: https://docs.litellm.ai/docs/providers/openai#openai-chat-completion-models\n",
    "MODEL_GPT_4O = \"openai/gpt-4.1\" # You can also try: gpt-4.1-mini, gpt-4o etc.\n",
    "\n",
    "# More supported models can be referenced here: https://docs.litellm.ai/docs/providers/anthropic\n",
    "MODEL_CLAUDE_SONNET = \"anthropic/claude-sonnet-4-20250514\" # You can also try: claude-opus-4-20250514 , claude-3-7-sonnet-20250219 etc\n",
    "\n",
    "print(\"\\nEnvironment configured.\")\n"
   ],
   "id": "c20e7762f06a9225",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Environment configured.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T11:59:17.099672Z",
     "start_time": "2025-11-03T11:59:17.084245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Weather tool\n",
    "def get_weather(city: str) -> dict:\n",
    "    \"\"\"Retrieves the current weather report for a given city.\n",
    "\n",
    "    Args:\n",
    "        city (str): name of city\n",
    "    Returns:\n",
    "        dict: A dictionary containing weather information\n",
    "              Includes a status key\n",
    "              If success, includes a report key with weather information\n",
    "              If error, includes an error_message key\n",
    "    \"\"\"\n",
    "    print(f\"--- Tool: get_weather called for city: {city} ---\")\n",
    "    city_normalized = city.lower()\n",
    "\n",
    "    # mock weather data\n",
    "    mock_weather_db = {\n",
    "        \"nairobi\": {\"status\": \"success\", \"report\": \"It's sunny today in Nairobi with a temperature of 24 degrees Celsius.\"},\n",
    "        \"london\": {\"status\": \"success\", \"report\": \"It's cloudy today in London with a temperature of 22 degrees Celsius.\"},\n",
    "        \"paris\": {\"status\": \"success\", \"report\": \"It's raining today in Paris with a temperature of 20 degrees Celsius.\"},\n",
    "        \"cape town\": {\"status\": \"success\", \"report\": \"It's sunny today in Cape Town with a temperature of 23 degrees Celsius.\"},\n",
    "    }\n",
    "\n",
    "    if city_normalized in mock_weather_db:\n",
    "        return mock_weather_db[city_normalized]\n",
    "    else:\n",
    "        return {\"status\": \"error\", \"error_message\": f\"City '{city}' not found in database.\"}\n",
    "\n",
    "print(get_weather(\"nairobi\"))\n",
    "print(get_weather(\"London\"))\n",
    "print(get_weather(\"Paris\"))\n",
    "print(get_weather(\"Cape Town\"))"
   ],
   "id": "c1b865d8e213de99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tool: get_weather called for city: nairobi ---\n",
      "{'status': 'success', 'report': \"It's sunny today in Nairobi with a temperature of 24 degrees Celsius.\"}\n",
      "--- Tool: get_weather called for city: London ---\n",
      "{'status': 'success', 'report': \"It's cloudy today in London with a temperature of 22 degrees Celsius.\"}\n",
      "--- Tool: get_weather called for city: Paris ---\n",
      "{'status': 'success', 'report': \"It's raining today in Paris with a temperature of 20 degrees Celsius.\"}\n",
      "--- Tool: get_weather called for city: Cape Town ---\n",
      "{'status': 'success', 'report': \"It's sunny today in Cape Town with a temperature of 23 degrees Celsius.\"}\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T11:59:22.917437Z",
     "start_time": "2025-11-03T11:59:22.900613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "AGENT_MODEL = MODEL_GEMINI_2_0_FLASH\n",
    "\n",
    "weather_agent = Agent(\n",
    "    name=\"weather_agent_v1\",\n",
    "    model=AGENT_MODEL,\n",
    "    description=\"Provides weather information for specified cities.\",\n",
    "    instruction=\"You are a helpful weather assistant. \"\n",
    "                \"When the user asks for weather in a given city, \"\n",
    "                \"use the 'get_weather' tool to find the current weather. \"\n",
    "                \"If the tool returns an error, inform the user. \"\n",
    "                \"If the tool is successful, present the weather report clearly.\",\n",
    "    tools=[get_weather],\n",
    ")\n",
    "print(f\"Agent '{weather_agent.name}' created using model '{AGENT_MODEL}'. \")"
   ],
   "id": "697906afa989d012",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 'weather_agent_v1' created using model 'gemini-2.5-flash'. \n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T11:59:30.662056Z",
     "start_time": "2025-11-03T11:59:30.604697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Session Management\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "APP_NAME = \"weather_agent_app\"\n",
    "USER_ID = \"user_2\"\n",
    "SESSION_ID = \"session_001\"\n",
    "\n",
    "# create session\n",
    "session = await session_service.create_session(\n",
    "    app_name=APP_NAME,\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID\n",
    ")\n",
    "print(f\"Session created: App='{APP_NAME}', User='{USER_ID}', Session='{SESSION_ID}'\")\n",
    "\n",
    "# create runner\n",
    "runner = Runner(\n",
    "    agent=weather_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service\n",
    ")\n",
    "print(f\"Runner created for agent '{runner.agent.name}'.'\")"
   ],
   "id": "3c5d023bd4035d7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session created: App='weather_agent_app', User='user_2', Session='session_001'\n",
      "Runner created for agent 'weather_agent_v1'.'\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T12:20:06.933184Z",
     "start_time": "2025-11-03T12:20:06.920419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from google.genai import types\n",
    "\n",
    "async def call_agent_async(query: str, runner, user_id, session_id):\n",
    "    \"\"\"Sends a query to the agent and prints the final response\"\"\"\n",
    "    print(f\"\\n>>> User Query: {query}\")\n",
    "\n",
    "    # format user message to adk format\n",
    "    content = types.Content(\n",
    "        role='user',\n",
    "        parts=[types.Part(text=query)]\n",
    "    )\n",
    "\n",
    "    final_response_text = \"Agent did not produce a final response.\"\n",
    "\n",
    "    # execute agent logic and yield events\n",
    "    # iterate through events to find the final answer\n",
    "\n",
    "    async for event in runner.run_async(\n",
    "        user_id=user_id,\n",
    "        session_id=session_id,\n",
    "        new_message=content\n",
    "    ):\n",
    "        # view events\n",
    "        # print(f\" [Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}, Content: {event.content}\")\n",
    "\n",
    "        # is_final_response() marks the concluding message for the turn\n",
    "        if event.is_final_response():\n",
    "            if event.content and event.content.parts:\n",
    "                final_response_text = event.content.parts[0].text\n",
    "            elif event.actions and event.actions.escalate:\n",
    "                final_response_text = f\"Agent escalated: {event.error_message or 'No specific message.'}\"\n",
    "            break\n",
    "\n",
    "\n",
    "    print(f\"\\n<<< Agent Final Response: {final_response_text}\")"
   ],
   "id": "974a6f07ca48eabe",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T12:20:20.441596Z",
     "start_time": "2025-11-03T12:20:10.784205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "async def run_conversations():\n",
    "    await call_agent_async(\"What is the weather in London?\", runner=runner, user_id=USER_ID, session_id=SESSION_ID)\n",
    "\n",
    "    await call_agent_async(\"How about Cape Town?\", runner=runner, user_id=USER_ID, session_id=SESSION_ID)\n",
    "\n",
    "    await call_agent_async(\"Can you tell me the weather in Nairobi?\", runner=runner, user_id=USER_ID, session_id=SESSION_ID)\n",
    "\n",
    "await run_conversations()"
   ],
   "id": "4fdbfb2141969b8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: What is the weather in London?\n",
      "--- Tool: get_weather called for city: London ---\n",
      "\n",
      "<<< Agent Final Response: The current weather in London is cloudy with a temperature of 22 degrees Celsius.\n",
      "\n",
      ">>> User Query: How about Cape Town?\n",
      "--- Tool: get_weather called for city: Cape Town ---\n",
      "\n",
      "<<< Agent Final Response: The current weather in Cape Town is sunny with a temperature of 23 degrees Celsius.\n",
      "\n",
      ">>> User Query: Can you tell me the weather in Nairobi?\n",
      "--- Tool: get_weather called for city: Nairobi ---\n",
      "\n",
      "<<< Agent Final Response: The current weather in Nairobi is sunny with a temperature of 24 degrees Celsius.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e73a28b479628a1c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
